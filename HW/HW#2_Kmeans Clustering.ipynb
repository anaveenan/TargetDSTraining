{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2.0:\n",
    "How do you merge  two sorted  lists/arrays of records of the form [key, value]? Where is this  used in Hadoop MapReduce? [Hint within the shuffle]\n",
    "What is  a combiner function in the context of Hadoop? \n",
    "Give an example where it can be used and justify why it should be used in the context of this problem.\n",
    "What is the Hadoop shuffle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer HW2.0\n",
    "By doing order inversion or value-to-key conversions.  This is used in memory in MapReduce.  Combiner performs further aggregations after the mapper function, thereby reducing the memory needed by the reducer if it is to perform any in-memory processing. \"It worth noting that Combiners can be used in this schema to exclude duplicates from category lists before data will be transmitted to Reducer.\" The Hadoop shuffle is when the partitioners group the keys , value pairs by keys before sending them to the reducer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2.1: Counters as a debugging aid (and for getting work done, but please use sparingly as they are heavy)\n",
    "\n",
    "Now, letâ€™s use MapReduce Counters to identify the number of complaints pertaining to debt collection, mortgage and other categories (all other categories get lumped into this one) in the consumer complaints dataset. Basically produce the distribution of the Product column in this dataset using counters (limited to 3 counters here).\n",
    "\n",
    "Hadoop offers Job Tracker, an UI tool to determine the status and statistics of all jobs. Using the job tracker UI, developers can view the Counters that have been created. Screenshot your  job tracker UI as your job completes and include it here. Make sure that your user defined counters are visible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer HW#2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_hw2_1_counters.py\n",
    "# MRJob development\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import csv \n",
    "\n",
    "cols = 'ComplaintID,Product,Sub-product,Issue,Subissue,State,ZIPcode,Submittedvia,Datereceived,Datesent,Company,Companyresponse,Timelyresponse,Consumerdisputed'.split(',')\n",
    "print cols\n",
    "\n",
    "class MRcounters(MRJob):\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        row = dict(zip(cols, [ a.strip() for a in csv.reader([line]).next()]))\n",
    "        #self.increment_counter('group', 'Num_mapper_calls', 1)\n",
    "\n",
    "        if row['Product'] == 'Product':\n",
    "            return\n",
    "        \n",
    "        elif row['Product'].lower() == 'debt collection':\n",
    "            self.increment_counter('debt collection' , 'Num_mapper_calls' , 1)\n",
    "                \n",
    "        elif row['Product'].lower() == 'mortgage':\n",
    "            self.increment_counter('mortgage' , 'Num_mapper_calls' , 1)\n",
    "                \n",
    "        else :\n",
    "            self.increment_counter('other' , 'Num_mapper_calls' , 1) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MRcounters.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MRJob rund code\n",
    "!python km_hw2_1_counters.py Consumer_Complaints.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No configs found; falling back on auto-configuration\n",
    "Creating temp directory c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw2_1_counters.Z001C9V.20160706.040015.428000\n",
    "Running step 1 of 1...\n",
    "\n",
    ">Counters: 3\n",
    "\t1. debt collection\n",
    "\t\tNum_mapper_calls=44372\n",
    "\t2. mortgage\n",
    "\t\tNum_mapper_calls=125752\n",
    "\t3. other\n",
    "\t\tNum_mapper_calls=142788\n",
    "       \n",
    "Streaming final output from c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw2_1_counters.Z001C9V.20160706.040015.428000\\output...\n",
    "Removing temp directory c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw2_1_counters.Z001C9V.20160706.040015.428000..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2.2: Analyze the performance of your Mappers, Combiners and Reducers using Counters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer HW#2.2 - a\n",
    "Perform a word count analysis of this single record dataset using a Mapper and Reducer based WordCount (i.e., no combiners are used here) using user defined Counters to count up how many time the mapper and reducer are called. What is the value of your user defined Mapper Counter, and Reducer Counter after completing this word count job. The answer  should be 1 and 4 respectively. Please explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo foo,foo,quux,labs,foo,bar,quux > input_hw_2_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_hw_2_2_counters_a.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import csv\n",
    "import string\n",
    "\n",
    "\n",
    "class MRCounter2_2(MRJob):\n",
    "    counter = 0 \n",
    "    def mapper(self, _ , line):\n",
    "        self.increment_counter('group', 'Mapper_Call_Num' , 1) \n",
    "        word = line.strip().lower().split(',')\n",
    "        #word = line.split('\\t')\n",
    "        print (word)\n",
    "        for item in word:\n",
    "            yield (item,1)\n",
    "           \n",
    "    def reducer(self, key, value):\n",
    "        self.increment_counter('group' , 'Reducer_Call_Num' , 1)\n",
    "        yield(key, sum(value))\n",
    "\n",
    "        #for w in word\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRCounter2_2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_hw_2_2_counters_a.py input_hw_2_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One run through the mapper creates a list that holds 4 keys and 1s.  The reducer receives a list of values one key at a time. \n",
    "# Thus, since there are 4 unique keys(words) in the list, the reducer runs 4 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer HW#2.2 - b\n",
    "Perform a word count analysis of the Issue column of the Consumer Complaints  Dataset using a Mapper and Reducer based WordCount (i.e., no combiners used anywhere)  using user defined Counters to count up how many times the mapper and reducer are called. What is the value of your user defined Mapper Counter, and Reducer Counter after completing your word count job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_hw_2_2_counters_b.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import csv , string, re\n",
    "\n",
    "\n",
    "class MRCounter2_2(MRJob):\n",
    "    counter = 0 \n",
    "    def mapper(self, _ , line):\n",
    "        self.increment_counter('group', 'Mapper_Call_Num' , 1) \n",
    "        word = line.strip().lower().split(',')\n",
    "        #word = line.split('\\t')\n",
    "        #print (word)\n",
    "        issue = word[3]\n",
    "        #print('issue:', issue)\n",
    "        word2 = issue.split(' ')\n",
    "        #print ('word2:' , word2)\n",
    "        for item in word2:\n",
    "            #print item\n",
    "            yield (item,1)\n",
    "            #break   \n",
    "    def reducer(self, key, value):\n",
    "        self.increment_counter('group' , 'Reducer_Call_Num' , 1)\n",
    "        yield(key, sum(value))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRCounter2_2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_hw_2_2_counters_b.py Consumer_Complaints.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "No configs found; falling back on auto-configuration\n",
    "Creating temp directory c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw_2_2_counters_b.Z001C9V.20160706.162736.861000\n",
    "Running step 1 of 1...\n",
    ">Counters: 1\n",
    "\t1. group\n",
    "\t\tMapper_Call_Num=312913\n",
    ">Counters: 2\n",
    "\t1. group\n",
    "\t\tMapper_Call_Num=312913\n",
    "\t\tReducer_Call_Num=172\n",
    "Streaming final output from c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw_2_2_counters_b.Z001C9V.20160706.162736.861000\\output...\n",
    "Removing temp directory c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw_2_2_counters_b.Z001C9V.20160706.162736.861000...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer HW#2.2 - c\n",
    "Perform a word count analysis of the Issue column of the Consumer Complaints  Dataset using a Mapper, Reducer, and standalone combiner (i.e., not an in-memory combiner) based WordCount using user defined Counters to count up how many time the mapper, combiner, reducer are called. What is the value of your user defined Mapper Counter, combiner counter, and Reducer Counter after completing your word count job. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_hw_2_2_counters_c.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import csv , string, re\n",
    "\n",
    "\n",
    "class MRCounter2_2(MRJob):\n",
    "    counter = 0 \n",
    "    def mapper(self, _ , line):\n",
    "        self.increment_counter('group', 'Mapper_Call_Num' , 1) \n",
    "        word = line.strip().lower().split(',')\n",
    "        #word = line.split('\\t')\n",
    "        #print (word)\n",
    "        issue = word[3]\n",
    "        #print('issue:', issue)\n",
    "        word2 = issue.split(' ')\n",
    "        #print ('word2:' , word2)\n",
    "        for item in word2:\n",
    "            #print item\n",
    "            yield (item,1)\n",
    "            #break \n",
    "    def combiner(self, key, value):\n",
    "        self.increment_counter('group' , 'Combiner_Call_Num' , 1)\n",
    "        yield (key , sum(value))\n",
    "        \n",
    "    def reducer(self, key, value):\n",
    "        self.increment_counter('group' , 'Reducer_Call_Num' , 1)\n",
    "        yield(key, sum(value))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRCounter2_2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_hw_2_2_counters_c.py Consumer_Complaints.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:\n",
    "No configs found; falling back on auto-configuration\n",
    "Creating temp directory c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw_2_2_counters_c.Z001C9V.20160706.164411.857000\n",
    "Running step 1 of 1...\n",
    ">Counters: 2\n",
    "\t1. group\n",
    "\t\tCombiner_Call_Num=319\n",
    "\t\tMapper_Call_Num=312913\n",
    ">Counters: 3\n",
    "\t1. group\n",
    "\t\tCombiner_Call_Num=319\n",
    "\t\tMapper_Call_Num=312913\n",
    "\t\tReducer_Call_Num=172\n",
    "Streaming final output from c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw_2_2_counters_c.Z001C9V.20160706.164411.857000\\output...\n",
    "Removing temp directory c:\\users\\z001c9v\\appdata\\local\\temp\\km_hw_2_2_counters_c.Z001C9V.20160706.164411.857000...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer HW2.2.1\n",
    "Using a single reducer perform a sort of the words in decreasing order of word counts. Present the top 50 terms and their frequency. If there are ties please sort the tokens in alphanumeric/string order. Present bottom 10 tokens (least frequent items). \n",
    "\n",
    "HINT: You will need a second MRStep for the sort part. Step 1 will be the usual word count, while step 2 will be a sort step. Please use the Hadoop/MRJob framework to perform the sort. Please do NOT use any of the built-in sorts  from  python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_hw_2_2_1_counters.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import csv , string, re\n",
    "#regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "class MRCounter2_2(MRJob):\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep ( mapper = self.mapper , \n",
    "                     combiner = self.combiner , \n",
    "                     reducer = self.reducer ) ,\n",
    "            MRStep ( mapper = self.mapper2 ,\n",
    "                    reducer = self.reducer2 )\n",
    "        ]\n",
    "\n",
    "    def __init__(self , *args, **kargs):\n",
    "        super(MRCounter2_2,self).__init__(*args, **kargs)\n",
    "        \n",
    "    def mapper(self, _ , line):\n",
    "        self.increment_counter('group', 'Mapper_Call_Num' , 1)        \n",
    "        word = line.strip().lower().split(',')\n",
    "        #word = line.split('\\t')\n",
    "        #print (word)\n",
    "        issue = word[3]\n",
    "        issue = re.sub('\\W+',' ',issue) \n",
    "        #print('issue:', issue)\n",
    "        word2 = issue.split(' ')\n",
    "        #print ('word2:' , word2)\n",
    "        for item in word2:\n",
    "            #print item\n",
    "            if item == u' ':\n",
    "                yield 'blankxxxx' , 1\n",
    "            yield (item,1)\n",
    "            #break \n",
    "    def combiner(self, key, value):\n",
    "        self.increment_counter('group' , 'Combiner_Call_Num' , 1)\n",
    "        yield (key , sum(value))\n",
    "        \n",
    "    def reducer(self, key, value):\n",
    "        self.increment_counter('group' , 'Reducer_Call_Num' , 1)\n",
    "        #output = {}\n",
    "        yield key , sum(value)\n",
    "        #output[key] = value\n",
    "        #yield None , output\n",
    "        \n",
    "    def mapper2(self, key , value):\n",
    "        self.increment_counter('group' , 'Mapper2_Call_Num' ,1)\n",
    "        num_int = format(\"%010d\" % value)\n",
    "        #num_sort = num_int + key\n",
    "        #print 'mapper2:' , (num_int , key)\n",
    "        #print '\\n'\n",
    "        #yield 'None' , list(num_int) , key\n",
    "        yield 'None' , (num_int , key)\n",
    "        \n",
    "        # yield None , (key , value)\n",
    "        '''\n",
    "        for word, num in value:\n",
    "            #num_int = format(\"%010d\" % num)\n",
    "            #print(num_int)\n",
    "            yield num , word        \n",
    "        '''\n",
    "\n",
    "        \n",
    "    '''\n",
    "        for number in value:\n",
    "            num_int = str(number)\n",
    "            print( \"'{num_int:0{max_num}d}'.\".format(number=number, max_num=max_num) )\n",
    "            #z10 = \"'{number:0{max_num}d}'\".format(number=number, max_num=max_num)\n",
    "            #z10 = str(z10)\n",
    "            #print number , key \n",
    "    '''\n",
    "    def reducer2(self, key , value):\n",
    "        self.increment_counter('group' , 'Reducer2_Call_Num' , 1)\n",
    "        #for word, num in value:\n",
    "        #    yield num , word\n",
    "        #print 'reducer2:' , (key , list(value) )\n",
    "        final_list = []\n",
    "        for p in value :\n",
    "            final_list.append(p)\n",
    "            final_list_bot = final_list[0:9]\n",
    "            final_list_top = final_list[-51:]\n",
    "        \n",
    "        for num , word in final_list_bot : \n",
    "            yield 'Bottom List:' , (num , word)\n",
    "        for num , word in final_list_top :\n",
    "            yield 'Top List:' , (num , word)\n",
    "            \n",
    "        #yield final_list[-51:]\n",
    "        #yield '\\n'\n",
    "        #yield final_list[0:9]\n",
    "            \n",
    "        #print final_list[-51:]\n",
    "        #print '\\n'\n",
    "        #print final_list[0:9]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRCounter2_2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_hw_2_2_1_counters.py Consumer_Complaints.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer HW2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_hw_2_2_1_counters.py --jobconf mapred.reduce.tasks=3 Consumer_Complaints.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see the same answer set as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer HW#2.2.3 - skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2.3: Shopping Cart Analysis\n",
    "   >Do some exploratory data analysis of this dataset guided by the following questions:. \n",
    "   >How many unique items are available from this supplier?\n",
    "   >Using a single reducer: Report your findings: such as number of unique products; largest basket; report the top 50 most frequently purchased items,  their frequency,   (break ties by sorting the products alphabetical order) etc. using Hadoop Map-Reduce.\n",
    "data: https://www.dropbox.com/s/zlfyiwa70poqg74/ProductPurchaseData.txt?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_2_3_shoppingcart_top_50.py \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import string , re \n",
    "\n",
    "class ShoppingBag_top50(MRJob) :\n",
    "    SORT_VALUES = True\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep ( mapper = self.mapper , \n",
    "                     combiner = self.combiner , \n",
    "                     reducer = self.reducer ) ,\n",
    "            MRStep ( mapper = self.mapper2 ,\n",
    "                    reducer = self.reducer2 )\n",
    "        ]\n",
    "\n",
    "    def __init__(self , *args, **kargs):\n",
    "        super(ShoppingBag_top50,self).__init__(*args, **kargs)\n",
    "\n",
    "    def mapper(self , _ , line) :\n",
    "        self.increment_counter('group' , 'Mapper_Call_Num' , 1)\n",
    "        \n",
    "        bags = line.strip().split(' ')\n",
    "        #basketsize = len(bags)\n",
    "        #print bags , len(bags)\n",
    "        for item in bags:\n",
    "            #print item , 1\n",
    "            yield item , 1\n",
    "            \n",
    "    def combiner(self, key, value):\n",
    "        self.increment_counter('group' , 'Combiner_Call_Num' , 1)\n",
    "        yield (key , sum(value))\n",
    "        \n",
    "    def reducer(self, key, value):\n",
    "        self.increment_counter('group' , 'Reducer_Call_Num' , 1)\n",
    "        #output = {}\n",
    "        yield key , sum(value)\n",
    "        #output[key] = value\n",
    "        #yield None , output\n",
    "        \n",
    "    def mapper2(self, key , value):\n",
    "        self.increment_counter('group' , 'Mapper2_Call_Num' ,1)\n",
    "        num_int = format(\"%010d\" % value)\n",
    "        #num_sort = num_int + key\n",
    "        #print 'mapper2:' , (num_int , key)\n",
    "        #print '\\n'\n",
    "        #yield 'None' , list(num_int) , key\n",
    "        yield 'None' , (num_int , key)\n",
    "        \n",
    "        # yield None , (key , value)\n",
    "\n",
    "\n",
    "    def reducer2(self, key , value):\n",
    "        self.increment_counter('group' , 'Reducer2_Call_Num' , 1)      \n",
    "        #for word, num in value:\n",
    "        #    yield num , word\n",
    "        #print 'reducer2:' , (key , list(value) )\n",
    "        final_list = []\n",
    "        for p in value :\n",
    "            final_list.append(p)\n",
    "            final_list_bot = final_list[0:9]\n",
    "            final_list_top = final_list[-51:]\n",
    "        \n",
    "        for num , word in final_list_bot : \n",
    "            yield 'Bottom List:' , (num , word)\n",
    "        for num , word in final_list_top :\n",
    "            yield 'Top List:' , (num , word)\n",
    "            \n",
    "        #yield final_list[-51:]\n",
    "        #yield '\\n'\n",
    "        #yield final_list[0:9]\n",
    "            \n",
    "        #print final_list[-51:]\n",
    "        #print '\\n'\n",
    "        #print final_list[0:9]\n",
    "\n",
    "       \n",
    "            \n",
    "if __name__ == '__main__' :\n",
    "    ShoppingBag_top50.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_2_3_shoppingcart_top_50.py ProductPurchaseData.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_2_3_shoppingcart_uniques.py \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import string , re \n",
    "\n",
    "class ShoppingBag_uniques(MRJob) :\n",
    "    def steps(self) :\n",
    "        return [\n",
    "                MRStep( mapper = self.mapper ,\n",
    "                        combiner = self.combiner , \n",
    "                        reducer = self.reducer\n",
    "                      ) \n",
    "            ,\n",
    "                MRStep( mapper = self.mapper2 ,\n",
    "              #          combiner = self.combiner2 , \n",
    "                        reducer = self.reducer2\n",
    "                      )      \n",
    "                ]\n",
    "        \n",
    "    def __init__(self, *args, **kargs) :\n",
    "        super(ShoppingBag_uniques, self).__init__(*args,**kargs)\n",
    "        \n",
    "    def mapper(self , _ , line) :\n",
    "        self.increment_counter(\"group\" , \"Mapper_Call_Num\" , 1)\n",
    "        \n",
    "        bags = line.strip().split(' ')\n",
    "        #basketsize = len(bags)\n",
    "        #print bags , len(bags)\n",
    "        for item in bags:\n",
    "            yield item , 1\n",
    "            \n",
    "    def combiner(self , item , value) :\n",
    "        self.increment_counter(\"group\" , \"Combiner_Call_Num\" , 1)\n",
    "        yield item , sum(value)\n",
    "        \n",
    "    def reducer(self , item , value) :\n",
    "        self.increment_counter(\"group\" , \"Reducer_Call_Num\" , 1)\n",
    "        yield item , sum(value)\n",
    "        yield '*' , 1\n",
    "       \n",
    "    def mapper2(self , item , value) :\n",
    "        self.increment_counter(\"group\" , \"Mapper2_Call_Num:\" , 1) \n",
    "        yield item , value\n",
    "        \n",
    "    def reducer2(self , item , value ) :\n",
    "        self.increment_counter(\"group\" , \"Reducer2_Call_Num:\" , 1)\n",
    "        total = 0\n",
    "        for values in value:\n",
    "            if item == '*' : \n",
    "                total += values\n",
    "            else : return\n",
    "        yield 'Total Uniques:' , total\n",
    "            \n",
    "if __name__ == '__main__' :\n",
    "    ShoppingBag_uniques.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_2_3_shoppingcart_uniques.py ProductPurchaseData.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile km_2_3_shoppingcart_largest.py \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import string , re \n",
    "\n",
    "class ShoppingBag_largest(MRJob) :\n",
    "    #def step(self) :\n",
    "    def __init__(self, *args, **kargs) :\n",
    "        super(ShoppingBag_largest, self).__init__(*args,**kargs)\n",
    "        self.maxvalue = ['' , 0]\n",
    "        \n",
    "    def mapper(self , _ , line) :\n",
    "        self.increment_counter('group' , 'Mapper_Call_Num' , 1)\n",
    "        \n",
    "        bags = line.strip().split(' ')\n",
    "        basketsize = len(bags)\n",
    "        #print bags , len(bags)\n",
    "        yield bags , basketsize\n",
    "        #for item in bags:\n",
    "         #   print item , 1\n",
    "            \n",
    "    def reducer(self , key , value) :\n",
    "        self.increment_counter(\"group\" , \"Reducer_Call_Num\" , 1)\n",
    "        test = 0\n",
    "        #maxvalue = ['',0]\n",
    "        for v in value:\n",
    "            test = v \n",
    "            #print self.maxvalue[1]\n",
    "            if test <= self.maxvalue[1] :\n",
    "                return\n",
    "            else :\n",
    "                self.maxvalue[0] = key\n",
    "                self.maxvalue[1] = test\n",
    "            \n",
    "        yield 'Largest Basket:' , self.maxvalue\n",
    "\n",
    "\n",
    "            \n",
    "if __name__ == '__main__' :\n",
    "    ShoppingBag_largest.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_2_3_shoppingcart_largest.py ProductPurchaseData.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1 OPTIONAL \n",
    "Using 2 reducers:  Report your findings such as number of unique products; largest basket; report the top 50 most frequently purchased items,  their frequency,  and their frequency (break ties by sorting the products alphabetical order) etc. using Hadoop Map-Reduce. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_2_3_shoppingcart_top_50.py --jobconf mapred.reduce.tasks=2 ProductPurchaseData.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_2_3_shoppingcart_uniques.py --jobconf mapred.reduce.tasks=2 ProductPurchaseData.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_2_3_shoppingcart_largest.py --jobconf mapred.reduce.tasks=2 ProductPurchaseData.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results: No difference in the run process for part #1, part #2, part#3 using 2 reducers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2.4. (Computationally prohibitive but then again Hadoop can handle this) Pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the total number of pairs for the ProductPurchaseData.txt data set.\n",
    "import math\n",
    "\n",
    "def item_combo(n):\n",
    "    pairs = n**2 / 2\n",
    "    return pairs\n",
    "\n",
    "num_pairs = item_combo(12592)\n",
    "print \"This is the total number of item pairs:\" + str(num_pairs)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: pg.195 Minin of Massive Data Sets:\n",
    "> \"For each basket we use a double loop to generate all the pairs.  Each time we generate a pair, we add 1 to its count. At the end, we examine all pairs and see which have counts that exceed the suppor theshold s; these are the frequent pairs.\n",
    "\n",
    "**Support Threshold = 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "add = open(\"PPD_shortlist.txt\" , 'w')\n",
    "base = open(\"ProductPurchaseData.txt\" , 'r')\n",
    "counter = 0 \n",
    "  \n",
    "for line in base:\n",
    "    counter += 1\n",
    "    if counter < 100 :\n",
    "        add.write(line)\n",
    "\n",
    "add.close()\n",
    "base.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting km_hw_2_4_Apriori.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile km_hw_2_4_Apriori.py \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import string , re\n",
    "\n",
    "counter = 0\n",
    "\n",
    "class Apriori_itemsets(MRJob):\n",
    "    \n",
    "    '''\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep ( mapper = self.mapper , \n",
    "                     combiner = self.combiner , \n",
    "                     reducer = self.reducer ) ,\n",
    "            MRStep ( mapper = self.mapper2 \n",
    "                   )\n",
    "        ]\n",
    "        \n",
    "    '''#,\n",
    "    #                reducer = self.reducer2 \n",
    "\n",
    "    def __init__(self, *args, **kargs) :\n",
    "        super(Apriori_itemsets,self).__init__(*args, **kargs)\n",
    "        self.L1 = {}\n",
    "        self.L2 = {}\n",
    "        self.item_list = {}\n",
    "        self.bags = []\n",
    "\n",
    "\n",
    "    def mapper(self , _ , line) :\n",
    "        self.increment_counter('group' , 'Mapper_Call_Num' , 1)\n",
    "        \n",
    "        bags = line.strip().split(' ') \n",
    "        #basketsize = len(bags)\n",
    "        #print bags , len(bags)\n",
    "        #for item in bags:\n",
    "         #   #print item , 1\n",
    "        #  yield item , 1\n",
    "        for i in bags:\n",
    "            # i not in self.item_list.keys() : return\n",
    "            #counter = 0 \n",
    "            for j in bags:\n",
    "                #counter += 1\n",
    "                #if counter > 5 : break\n",
    "                #if j not in self.item_list.keys() : return\n",
    "                while i <> j:\n",
    "                    #self.L2[i+j] += 1\n",
    "                    yield i+j , 1         \n",
    "            \n",
    "    def combiner(self, key, value):\n",
    "        self.increment_counter('group' , 'Combiner_Call_Num' , 1)\n",
    "        yield (key , sum(value))\n",
    "    \n",
    "    def reducer(self, key, value):\n",
    "        #print key , sum(value)\n",
    "        self.increment_counter('group' , 'Reducer_Call_Num' , 1)\n",
    "        total = sum(value)\n",
    "        #print key , total\n",
    "        if total >= 10 : \n",
    "            #print key , total\n",
    "            self.item_list[key] = total\n",
    "        yield 'None' , self.item_list\n",
    "\n",
    "            \n",
    "    '''\n",
    "    def mapper2(self, key , line):\n",
    "        self.increment_counter('group' , 'Mapper2_Call_Num' ,1)\n",
    "        print  key , line\n",
    "        print '\\n'\n",
    "        #bags = line.strip().split(' ')\n",
    "        #basketsize = len(bags)\n",
    "        #print self.item_list\n",
    "\n",
    "        for i in bags:\n",
    "            if i not in self.item_list.keys() : return\n",
    "            counter = 0 \n",
    "            for j in bags:\n",
    "                if counter > 5 : break\n",
    "                if j not in self.item_list.keys() : return\n",
    "                while i <> j:\n",
    "                    self.L2[i+j] +1\n",
    "                    print i+j , 1 \n",
    "            #print item , 1\n",
    "            #yield item , 1\n",
    "\n",
    "        # yield None , (key , value)\n",
    "        \n",
    "    \n",
    "    def reducer2(self, key , value):\n",
    "        self.increment_counter('group' , 'Reducer2_Call_Num' , 1)      \n",
    "        #for word, num in value:\n",
    "        #    yield num , word\n",
    "        #print 'reducer2:' , (key , list(value) )\n",
    "        final_list = []\n",
    "        for p in value :\n",
    "            final_list.append(p)\n",
    "            final_list_bot = final_list[0:9]\n",
    "            final_list_top = final_list[-51:]\n",
    "        \n",
    "        for num , word in final_list_bot : \n",
    "            yield 'Bottom List:' , (num , word)\n",
    "        for num , word in final_list_top :\n",
    "            yield 'Top List:' , (num , word)\n",
    "            \n",
    "        #yield final_list[-51:]\n",
    "        #yield '\\n'\n",
    "        #yield final_list[0:9]\n",
    "            \n",
    "        #print final_list[-51:]\n",
    "        #print '\\n'\n",
    "        #print final_list[0:9]\n",
    "    '''\n",
    "               \n",
    "        \n",
    "if __name__ == \"__main__\" :\n",
    "    Apriori_itemsets.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python km_hw_2_4_Apriori.py ProductPurchaseData.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
